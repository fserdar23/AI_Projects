{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "058d104a-074a-47b0-91b5-4a7f324c924a",
   "metadata": {},
   "source": [
    "# Three generations seeking romance - Regression & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b2b68-1021-4639-b773-d16ab16678fd",
   "metadata": {},
   "source": [
    "<img src=\"https://kutahyaekspres.com/wp-content/uploads/2023/10/ask.jpg\" width=\"530\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af369eb9-1425-43df-864e-fa16d09c1180",
   "metadata": {},
   "source": [
    "Bu bir Regresyon ve Sınıflandırma projesidir\n",
    "\n",
    "YAŞA VE NESİLE GÖRE ÇEVRİMİÇİ BULUŞMACILARIN PROFİLİNİ ÇIKARMAK İÇİN VERİ BİLİMİ YAKLAŞIMI</br>\n",
    "1 - Arkadaşlık profiliniz yaşınızı tahmin edebilir mi? Regresyon Derin Öğrenme</br>\n",
    "2 - Arkadaşlık profiliniz ait olduğunuz nesli tahmin edebilir mi? (Y Kuşağı, X Kuşağı veya Bebek Patlaması Kuşağı) Sınıflandırma - Derin Öğrenme\n",
    "OKCupid arkadaşlık platformundan yaklaşık 60.000 anonim girişin bulunduğu bir veri kümesini kullanarak, yukarıdaki soruları denetlenen makine öğrenme tekniklerini kullanarak keşfedeceksiniz.</br> Kullanıcı profillerinin farklı yönlerini veya özelliklerini inceleyecek ve en tatmin edici puanları elde etmek için hangilerini modellerinize entegre edeceğinizi göreceksiniz. İlk soruyu ele almak için regresyon tekniklerini ve ikinci soruyu ele almak için sınıflandırma modellerini kullanacaksınız.\n",
    "“last_online” özelliğinin en düşük ve en yüksek değerlerini inceleyerek, OKCupid veri kümesinin 2011 veya 2012 civarında tarihli olduğu sonucuna varılabilir. O zamanlar, bir “Y kuşağı” 18 ila 32 yaş aralığında, bir “X kuşağı” 33 ila 47 yaş aralığında ve “Boomers” ise 48 ila 70 yaş aralığında olurdu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f60a9-f6d5-4c87-8c7a-4af1a54f4f41",
   "metadata": {},
   "source": [
    "<a href=\"https://drive.google.com/file/d/1HPMncPYf-CYgvs-KBCY2hyvqyKrwLPea/view?usp=sharing\">Dataya buradan Erişebilirsiniz</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa96627-0a51-405b-a1d0-2839be3f267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import normalize, scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d297f9e7-fd13-4dbe-8d2f-060e2c89a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"profiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9751f9ff-9933-428f-95ff-b2246b3bf8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60552, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda558cf-4e82-47cf-95bb-3d7bd40b7c65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            51038\n",
       "body_type      51886\n",
       "diet           54791\n",
       "drinks         51540\n",
       "drugs          53337\n",
       "education      52093\n",
       "essay0         51885\n",
       "essay1         52205\n",
       "essay2         52503\n",
       "essay3         52862\n",
       "essay4         52673\n",
       "essay5         52738\n",
       "essay6         53200\n",
       "essay7         52999\n",
       "essay8         54191\n",
       "essay9         52998\n",
       "ethnicity      51987\n",
       "height         51038\n",
       "income         51038\n",
       "job            52369\n",
       "last_online    51038\n",
       "location       51038\n",
       "offspring      56666\n",
       "orientation    51038\n",
       "pets           54200\n",
       "religion       54291\n",
       "sex            51038\n",
       "sign           52776\n",
       "smokes         51956\n",
       "speaks         51044\n",
       "status         51038\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f45946e4-f492-4f8c-8684-750861942a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tüm sütunları boş olan satırları kaldırdık\n",
    "df=df.dropna(how='all') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2b478-5a4b-4531-a246-3c027c7d31f3",
   "metadata": {},
   "source": [
    "###  EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d869800a-98a2-4806-90a1-1cc94768e89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>about me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh.&lt;br /&gt;\\nranting about a go...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>...</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>i am a chef: this is what that means.&lt;br /&gt;\\n1...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age       body_type               diet    drinks      drugs  \\\n",
       "0  22.0  a little extra  strictly anything  socially      never   \n",
       "1  35.0         average       mostly other     often  sometimes   \n",
       "2  38.0            thin           anything  socially        NaN   \n",
       "\n",
       "                        education  \\\n",
       "0   working on college/university   \n",
       "1           working on space camp   \n",
       "2  graduated from masters program   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:<br />\\n<br />\\ni would love to think...   \n",
       "1  i am a chef: this is what that means.<br />\\n1...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh.<br />\\nranting about a go...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "\n",
       "                                              essay3  ...  \\\n",
       "0  the way i look. i am a six foot half asian, ha...  ...   \n",
       "1                                                NaN  ...   \n",
       "2  my large jaw and large glasses are the physica...  ...   \n",
       "\n",
       "                          location  \\\n",
       "0  south san francisco, california   \n",
       "1              oakland, california   \n",
       "2        san francisco, california   \n",
       "\n",
       "                                      offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, but might want them    straight   \n",
       "1  doesn&rsquo;t have kids, but might want them    straight   \n",
       "2                                           NaN    straight   \n",
       "\n",
       "                        pets                                  religion sex  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
       "2                   has cats                                       NaN   m   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "\n",
       "                                              speaks     status  \n",
       "0                                            english     single  \n",
       "1  english (fluently), spanish (poorly), french (...     single  \n",
       "2                               english, french, c++  available  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e83654-4ba9-4435-987f-b5f685b10f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9514, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b81d1721-e413-4558-a72b-0cc6820e2a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "body_type       848\n",
       "diet           3753\n",
       "drinks          502\n",
       "drugs          2299\n",
       "education      1055\n",
       "essay0          847\n",
       "essay1         1167\n",
       "essay2         1465\n",
       "essay3         1824\n",
       "essay4         1635\n",
       "essay5         1700\n",
       "essay6         2162\n",
       "essay7         1961\n",
       "essay8         3153\n",
       "essay9         1960\n",
       "ethnicity       949\n",
       "height            0\n",
       "income            0\n",
       "job            1331\n",
       "last_online       0\n",
       "location          0\n",
       "offspring      5628\n",
       "orientation       0\n",
       "pets           3162\n",
       "religion       3253\n",
       "sex               0\n",
       "sign           1738\n",
       "smokes          918\n",
       "speaks            6\n",
       "status            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad634a82-254c-4838-86f9-23632035220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9514 entries, 0 to 9513\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          9514 non-null   float64\n",
      " 1   body_type    8666 non-null   object \n",
      " 2   diet         5761 non-null   object \n",
      " 3   drinks       9012 non-null   object \n",
      " 4   drugs        7215 non-null   object \n",
      " 5   education    8459 non-null   object \n",
      " 6   essay0       8667 non-null   object \n",
      " 7   essay1       8347 non-null   object \n",
      " 8   essay2       8049 non-null   object \n",
      " 9   essay3       7690 non-null   object \n",
      " 10  essay4       7879 non-null   object \n",
      " 11  essay5       7814 non-null   object \n",
      " 12  essay6       7352 non-null   object \n",
      " 13  essay7       7553 non-null   object \n",
      " 14  essay8       6361 non-null   object \n",
      " 15  essay9       7554 non-null   object \n",
      " 16  ethnicity    8565 non-null   object \n",
      " 17  height       9514 non-null   float64\n",
      " 18  income       9514 non-null   float64\n",
      " 19  job          8183 non-null   object \n",
      " 20  last_online  9514 non-null   object \n",
      " 21  location     9514 non-null   object \n",
      " 22  offspring    3886 non-null   object \n",
      " 23  orientation  9514 non-null   object \n",
      " 24  pets         6352 non-null   object \n",
      " 25  religion     6261 non-null   object \n",
      " 26  sex          9514 non-null   object \n",
      " 27  sign         7776 non-null   object \n",
      " 28  smokes       8596 non-null   object \n",
      " 29  speaks       9508 non-null   object \n",
      " 30  status       9514 non-null   object \n",
      "dtypes: float64(3), object(28)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa76d588-e3e0-420e-a0a7-817fdc5b8a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sometimes', 'no', nan, 'when drinking', 'yes', 'trying to quit'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"smokes\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e2c5910-7d78-47cc-bd11-77532cbb772a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smokes\n",
       "no                7011\n",
       "sometimes          565\n",
       "when drinking      480\n",
       "yes                307\n",
       "trying to quit     233\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"smokes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c158715-e13e-4053-bb1e-5dbb67e44d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['straight', 'bisexual', 'gay'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"orientation\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0cd41b0-8ae4-4760-8bcd-35a62e8263e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orientation\n",
       "straight    8191\n",
       "gay          897\n",
       "bisexual     426\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"orientation\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c175984d-d989-4ac9-8722-08087de84648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['never', 'sometimes', nan, 'often'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"drugs\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bcad868-9e23-4f44-96b3-edf8b732cc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugs\n",
       "never        5972\n",
       "sometimes    1181\n",
       "often          62\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"drugs\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc3fe8f1-4ed4-4cb4-b270-556e6ed0acf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['socially', 'often', 'not at all', 'rarely', nan, 'very often',\n",
       "       'desperately'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"drinks\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f986186-f26c-45cc-b562-feadc5727e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drinks\n",
       "socially       6679\n",
       "rarely          911\n",
       "often           809\n",
       "not at all      509\n",
       "very often       54\n",
       "desperately      50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"drinks\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a2a9fc4-634b-4523-8c99-525020b1cc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['doesn&rsquo;t have kids, but might want them', nan,\n",
       "       'doesn&rsquo;t want kids',\n",
       "       'doesn&rsquo;t have kids, but wants them',\n",
       "       'doesn&rsquo;t have kids', 'wants kids', 'has a kid', 'has kids',\n",
       "       'doesn&rsquo;t have kids, and doesn&rsquo;t want any',\n",
       "       'has kids, but doesn&rsquo;t want more',\n",
       "       'has a kid, but doesn&rsquo;t want more',\n",
       "       'has a kid, and wants more', 'has kids, and might want more',\n",
       "       'might want kids', 'has a kid, and might want more',\n",
       "       'has kids, and wants more'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"offspring\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "feaf2b09-938b-4577-9014-a9c982d4f121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a little extra', 'average', 'thin', 'athletic', 'fit', nan,\n",
       "       'skinny', 'curvy', 'full figured', 'jacked', 'rather not say',\n",
       "       'used up', 'overweight'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"body_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10ee322d-c235-43b1-aa70-81fed07ef825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['likes dogs and likes cats', 'has cats', 'likes cats', nan,\n",
       "       'has dogs and likes cats', 'likes dogs and has cats',\n",
       "       'likes dogs and dislikes cats', 'has dogs',\n",
       "       'has dogs and dislikes cats', 'likes dogs',\n",
       "       'has dogs and has cats', 'dislikes dogs and has cats',\n",
       "       'dislikes dogs and dislikes cats', 'dislikes cats',\n",
       "       'dislikes dogs and likes cats', 'dislikes dogs'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pets\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95798db9-9fe7-43a8-89f3-b39a32186964",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eec0ccec-10c3-478f-99dd-a377363368fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['smokes'] = df['smokes'].replace({ \n",
    "    'sometimes': 'yes',\n",
    "    'when drinking': 'yes',\n",
    "    'trying to quit': 'yes',\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7af2942c-4ab8-4aa4-b7b7-2cbd4df15b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_type'] = df['body_type'].replace({ \n",
    "    'a little extra': 'weight',\n",
    "    'average': 'fit',\n",
    "    'athletic': 'fit',\n",
    "    'skinny': 'thin',\n",
    "    'full figured': 'weight',\n",
    "    'jacked': 'fit',\n",
    "    'rather not say': \"fit\",\n",
    "    'used up': 'thin',\n",
    "    'curvy': 'fit'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92f784cf-3003-46f6-85fd-12e923bd89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['offspring'] = df['offspring'].replace({ \n",
    "    'doesn&rsquo;t have kids': 'No',\n",
    "    'doesn&rsquo;t want kids': 'No',\n",
    "    'doesn&rsquo;t have kids, but wants them': 'No',\n",
    "    'wants kids': 'No',\n",
    "    'has a kid': 'Yes',\n",
    "    'has kids': 'Yes',\n",
    "    'doesn&rsquo;t have kids, and doesn&rsquo;t want any': \"No\",\n",
    "    'has kids, but doesn&rsquo;t want more': 'Yes',\n",
    "    'has a kid, but doesn&rsquo;t want more': 'Yes',\n",
    "    'has a kid, and wants more': 'Yes',\n",
    "    'has kids, and might want more': 'Yes',\n",
    "    'might want kids': 'No',\n",
    "    'has a kid, and might want more': 'Yes',\n",
    "    'has kids, and wants more': 'Yes',\n",
    "    'doesn&rsquo;t have kids, but might want them':\"No\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caed2adb-3857-4839-b702-e4590a2f8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pets'] = df['pets'].replace({ \n",
    "    'likes dogs and likes cats': \"all\",\n",
    "    'has cats': \"cats\",\n",
    "    'likes cats': \"cats\",\n",
    "    'has dogs and likes cats':\"all\",\n",
    "    'has dogs': \"dogs\",\n",
    "    'has dogs and dislikes cats': \"cats\",\n",
    "    'likes dogs': \"cats\",\n",
    "    'has dogs and has cats': \"all\",\n",
    "    'dislikes dogs and has cats': \"cats\",\n",
    "    'dislikes dogs and dislikes cats': \"not\",\n",
    "    'dislikes cats': \"cats\",\n",
    "    'dislikes dogs and likes cats':\"cats\",\n",
    "    'dislikes dogs': \"cats\",\n",
    "    'likes dogs and dislikes cats': \"cats\",\n",
    "    'likes dogs and has cats':\"all\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efdcf78-b6d1-42df-a3f4-b410cec35d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64b0666e-b2f4-4d53-a477-ef971cf3f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"age\",\"height\",\"sex\",\"smokes\",\"orientation\",\"drugs\",\"drinks\",\"body_type\",\"offspring\",\"pets\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "079d813e-67f0-44c5-b157-fbbec7505b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "height            0\n",
       "sex               0\n",
       "smokes          918\n",
       "orientation       0\n",
       "drugs          2299\n",
       "drinks          502\n",
       "body_type       848\n",
       "offspring      5628\n",
       "pets           3162\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "566ab401-0be0-48fb-9934-2b7d54bd93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"smokes\"]=df[\"smokes\"].fillna(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39f9f595-6c76-4246-8248-052e1790b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"drugs\"]=df[\"drugs\"].fillna(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8881085-9d1c-464b-b8fa-164de788adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"drinks\"]=df[\"drinks\"].fillna(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d013653-c2da-4777-bb56-7786cecf5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"body_type\"]=df[\"body_type\"].fillna(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22cca278-f3fd-4a4c-b948-8a5a418ad053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"offspring\"]=df[\"offspring\"].fillna(\"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "151d3c34-6a0f-4859-9506-5a357be8e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pets\"]=df[\"pets\"].fillna(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd4e1a-9faa-40cb-b3db-dd1b7833515d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c512755a-85e8-49dc-bb80-e8284958a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kuşaklandırma fonksiyonu\n",
    "# Kuşakalra \"Millenicom\" gibi yazı şeklinde değer verirsek accuracy score çok düşük çıkıyor\n",
    "def kuşak_belirle(yas):\n",
    "  if 18 <= yas <= 32:\n",
    "    return 1\n",
    "  elif 33 <= yas <= 47:\n",
    "    return 2\n",
    "  elif 48 <= yas <= 70:\n",
    "    return 3\n",
    "  else:\n",
    "    return 4\n",
    "\n",
    "# Kuşak sütununu ekleme\n",
    "df['Kusak']= df['age'].apply(kuşak_belirle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b244f83c-a696-47db-9268-e15e5301da8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "      <th>orientation</th>\n",
       "      <th>drugs</th>\n",
       "      <th>drinks</th>\n",
       "      <th>body_type</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>Kusak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>m</td>\n",
       "      <td>yes</td>\n",
       "      <td>straight</td>\n",
       "      <td>never</td>\n",
       "      <td>socially</td>\n",
       "      <td>weight</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>often</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>no</td>\n",
       "      <td>socially</td>\n",
       "      <td>thin</td>\n",
       "      <td>No</td>\n",
       "      <td>cats</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>no</td>\n",
       "      <td>socially</td>\n",
       "      <td>thin</td>\n",
       "      <td>No</td>\n",
       "      <td>cats</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>never</td>\n",
       "      <td>socially</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509</th>\n",
       "      <td>28.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>never</td>\n",
       "      <td>socially</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510</th>\n",
       "      <td>31.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>m</td>\n",
       "      <td>yes</td>\n",
       "      <td>gay</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>socially</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9511</th>\n",
       "      <td>34.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>yes</td>\n",
       "      <td>gay</td>\n",
       "      <td>no</td>\n",
       "      <td>socially</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9512</th>\n",
       "      <td>29.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>gay</td>\n",
       "      <td>never</td>\n",
       "      <td>rarely</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9513</th>\n",
       "      <td>49.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>never</td>\n",
       "      <td>rarely</td>\n",
       "      <td>overweight</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9514 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  height sex smokes orientation      drugs    drinks   body_type  \\\n",
       "0     22.0    75.0   m    yes    straight      never  socially      weight   \n",
       "1     35.0    70.0   m     no    straight  sometimes     often         fit   \n",
       "2     38.0    68.0   m     no    straight         no  socially        thin   \n",
       "3     23.0    71.0   m     no    straight         no  socially        thin   \n",
       "4     29.0    66.0   m     no    straight      never  socially         fit   \n",
       "...    ...     ...  ..    ...         ...        ...       ...         ...   \n",
       "9509  28.0    73.0   m     no    straight      never  socially         fit   \n",
       "9510  31.0    72.0   m    yes         gay  sometimes  socially         fit   \n",
       "9511  34.0    71.0   m    yes         gay         no  socially         fit   \n",
       "9512  29.0    70.0   m     no         gay      never    rarely         fit   \n",
       "9513  49.0    64.0   f     no    straight      never    rarely  overweight   \n",
       "\n",
       "     offspring  pets  Kusak  \n",
       "0           No   all      1  \n",
       "1           No   all      2  \n",
       "2           No  cats      2  \n",
       "3           No  cats      1  \n",
       "4           No   all      1  \n",
       "...        ...   ...    ...  \n",
       "9509        No   all      1  \n",
       "9510        No   not      1  \n",
       "9511        No   all      2  \n",
       "9512        No   all      1  \n",
       "9513        No   all      3  \n",
       "\n",
       "[9514 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef3e1b5e-6cf8-47da-a08b-cbf76e7785d0",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59901aa8-f361-4957-b361-1bad410aa0c2",
   "metadata": {},
   "source": [
    "#### Regression ile Yaş Tahmini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fdbdad9-63ae-4695-bad3-ea7e8cf1b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\"age\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "decef8fe-cdf9-4cf1-85a2-84f65b8187dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "322601fe-dc39-4740-8d4e-4a3ccf96a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.get_dummies(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9d8f58f-533b-47ff-a6b6-001c4ee24d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>Kusak</th>\n",
       "      <th>sex_f</th>\n",
       "      <th>sex_m</th>\n",
       "      <th>smokes_no</th>\n",
       "      <th>smokes_yes</th>\n",
       "      <th>orientation_bisexual</th>\n",
       "      <th>orientation_gay</th>\n",
       "      <th>orientation_straight</th>\n",
       "      <th>drugs_never</th>\n",
       "      <th>...</th>\n",
       "      <th>body_type_fit</th>\n",
       "      <th>body_type_overweight</th>\n",
       "      <th>body_type_thin</th>\n",
       "      <th>body_type_weight</th>\n",
       "      <th>offspring_No</th>\n",
       "      <th>offspring_Yes</th>\n",
       "      <th>pets_all</th>\n",
       "      <th>pets_cats</th>\n",
       "      <th>pets_dogs</th>\n",
       "      <th>pets_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509</th>\n",
       "      <td>73.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510</th>\n",
       "      <td>72.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9511</th>\n",
       "      <td>71.0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9512</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9513</th>\n",
       "      <td>64.0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9514 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      height  Kusak  sex_f  sex_m  smokes_no  smokes_yes  \\\n",
       "0       75.0      1  False   True      False        True   \n",
       "1       70.0      2  False   True       True       False   \n",
       "2       68.0      2  False   True       True       False   \n",
       "3       71.0      1  False   True       True       False   \n",
       "4       66.0      1  False   True       True       False   \n",
       "...      ...    ...    ...    ...        ...         ...   \n",
       "9509    73.0      1  False   True       True       False   \n",
       "9510    72.0      1  False   True      False        True   \n",
       "9511    71.0      2  False   True      False        True   \n",
       "9512    70.0      1  False   True       True       False   \n",
       "9513    64.0      3   True  False       True       False   \n",
       "\n",
       "      orientation_bisexual  orientation_gay  orientation_straight  \\\n",
       "0                    False            False                  True   \n",
       "1                    False            False                  True   \n",
       "2                    False            False                  True   \n",
       "3                    False            False                  True   \n",
       "4                    False            False                  True   \n",
       "...                    ...              ...                   ...   \n",
       "9509                 False            False                  True   \n",
       "9510                 False             True                 False   \n",
       "9511                 False             True                 False   \n",
       "9512                 False             True                 False   \n",
       "9513                 False            False                  True   \n",
       "\n",
       "      drugs_never  ...  body_type_fit  body_type_overweight  body_type_thin  \\\n",
       "0            True  ...          False                 False           False   \n",
       "1           False  ...           True                 False           False   \n",
       "2           False  ...          False                 False            True   \n",
       "3           False  ...          False                 False            True   \n",
       "4            True  ...           True                 False           False   \n",
       "...           ...  ...            ...                   ...             ...   \n",
       "9509         True  ...           True                 False           False   \n",
       "9510        False  ...           True                 False           False   \n",
       "9511        False  ...           True                 False           False   \n",
       "9512         True  ...           True                 False           False   \n",
       "9513         True  ...          False                  True           False   \n",
       "\n",
       "      body_type_weight  offspring_No  offspring_Yes  pets_all  pets_cats  \\\n",
       "0                 True          True          False      True      False   \n",
       "1                False          True          False      True      False   \n",
       "2                False          True          False     False       True   \n",
       "3                False          True          False     False       True   \n",
       "4                False          True          False      True      False   \n",
       "...                ...           ...            ...       ...        ...   \n",
       "9509             False          True          False      True      False   \n",
       "9510             False          True          False     False      False   \n",
       "9511             False          True          False      True      False   \n",
       "9512             False          True          False      True      False   \n",
       "9513             False          True          False      True      False   \n",
       "\n",
       "      pets_dogs  pets_not  \n",
       "0         False     False  \n",
       "1         False     False  \n",
       "2         False     False  \n",
       "3         False     False  \n",
       "4         False     False  \n",
       "...         ...       ...  \n",
       "9509      False     False  \n",
       "9510      False      True  \n",
       "9511      False     False  \n",
       "9512      False     False  \n",
       "9513      False     False  \n",
       "\n",
       "[9514 rows x 30 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "799f8640-aa90-4c2f-9de7-3c210d7db5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scale(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb4e36bf-47c5-46ee-8dca-0c07aa89b683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.70616204, -0.69686557, -0.82248147, ..., -0.5206491 ,\n",
       "        -0.27810283, -0.71257663],\n",
       "       [ 0.42575994,  0.87645646, -0.82248147, ..., -0.5206491 ,\n",
       "        -0.27810283, -0.71257663],\n",
       "       [-0.0864009 ,  0.87645646, -0.82248147, ...,  1.9206794 ,\n",
       "        -0.27810283, -0.71257663],\n",
       "       ...,\n",
       "       [ 0.68184036,  0.87645646, -0.82248147, ..., -0.5206491 ,\n",
       "        -0.27810283, -0.71257663],\n",
       "       [ 0.42575994, -0.69686557, -0.82248147, ..., -0.5206491 ,\n",
       "        -0.27810283, -0.71257663],\n",
       "       [-1.11072258,  2.4497785 ,  1.21583286, ..., -0.5206491 ,\n",
       "        -0.27810283, -0.71257663]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85a2154a-c2c3-46c7-b9b6-298dbc3e298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\",100)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,SGDRegressor,Ridge,Lasso,ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree, ExtraTreeRegressor\n",
    "#pip install xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def algo_test(x,y):\n",
    "        #Bütün modelleri tanımlıyorum\n",
    "        L=LinearRegression()\n",
    "        R=Ridge()\n",
    "        Lass=Lasso()\n",
    "        E=ElasticNet()\n",
    "        sgd=SGDRegressor()\n",
    "        ETR=ExtraTreeRegressor()\n",
    "        GBR=GradientBoostingRegressor()\n",
    "        kn=KNeighborsRegressor()\n",
    "        rkn=RadiusNeighborsRegressor(radius=1.0)\n",
    "        ada=AdaBoostRegressor()\n",
    "        dt=DecisionTreeRegressor()\n",
    "        xgb=XGBRegressor()\n",
    "        svr=SVR()\n",
    "        mlp_regressor = MLPRegressor()\n",
    "\n",
    "       \n",
    "        \n",
    "        algos=[L,R,Lass,E,sgd,ETR,GBR,ada,kn,dt,xgb,svr,mlp_regressor]\n",
    "        algo_names=['Linear','Ridge','Lasso','ElasticNet','SGD','Extra Tree','Gradient Boosting',\n",
    "                    'KNeighborsRegressor','AdaBoost','Decision Tree','XGBRegressor','SVR','mlp_regressor']\n",
    "        \n",
    "        x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=.20,random_state=42)\n",
    "        \n",
    "        r_squared= []\n",
    "        rmse= []\n",
    "        mae= []\n",
    "        \n",
    "        #Hata ve doğruluk oranlarını bir tablo haline getirmek için bir dataframe oluşturuyorum\n",
    "        result=pd.DataFrame(columns=['R_Squared','RMSE','MAE'],index=algo_names)\n",
    "        \n",
    "        \n",
    "        for algo in algos:\n",
    "            p=algo.fit(x_train,y_train).predict(x_test)\n",
    "            r_squared.append(r2_score(y_test,p))\n",
    "            rmse.append(mean_squared_error(y_test,p)**.5)\n",
    "            mae.append(mean_absolute_error(y_test,p))\n",
    "        \n",
    "            \n",
    "\n",
    "        #result adlı tabloya doğruluk ve hata oranlarımı yerleştiriyorum\n",
    "        result.R_Squared=r_squared\n",
    "        result.RMSE=rmse\n",
    "        result.MAE=mae\n",
    "        \n",
    "       #oluşturduğum result tablosunu doğruluk oranına (r2_score) göre sıralayıp dönüyor\n",
    "        rtable=result.sort_values('R_Squared',ascending=False)\n",
    "        return rtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "113c6a2b-045b-4ddf-8aed-dd14b1fb87cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.844722</td>\n",
       "      <td>3.756651</td>\n",
       "      <td>3.071571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.839510</td>\n",
       "      <td>3.819184</td>\n",
       "      <td>3.150264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_regressor</th>\n",
       "      <td>0.834490</td>\n",
       "      <td>3.878447</td>\n",
       "      <td>3.168782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.832753</td>\n",
       "      <td>3.898751</td>\n",
       "      <td>3.172759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.830508</td>\n",
       "      <td>3.924827</td>\n",
       "      <td>3.174840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>0.830366</td>\n",
       "      <td>3.926469</td>\n",
       "      <td>3.175538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.829798</td>\n",
       "      <td>3.933036</td>\n",
       "      <td>3.178458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.810262</td>\n",
       "      <td>4.152624</td>\n",
       "      <td>3.253018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.774600</td>\n",
       "      <td>4.526088</td>\n",
       "      <td>3.429478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extra Tree</th>\n",
       "      <td>0.739850</td>\n",
       "      <td>4.862483</td>\n",
       "      <td>3.797376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.738008</td>\n",
       "      <td>4.879668</td>\n",
       "      <td>3.778136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.718953</td>\n",
       "      <td>5.054002</td>\n",
       "      <td>3.723071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.665066</td>\n",
       "      <td>5.517286</td>\n",
       "      <td>4.012822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     R_Squared      RMSE       MAE\n",
       "Gradient Boosting     0.844722  3.756651  3.071571\n",
       "KNeighborsRegressor   0.839510  3.819184  3.150264\n",
       "mlp_regressor         0.834490  3.878447  3.168782\n",
       "XGBRegressor          0.832753  3.898751  3.172759\n",
       "Ridge                 0.830508  3.924827  3.174840\n",
       "Linear                0.830366  3.926469  3.175538\n",
       "SGD                   0.829798  3.933036  3.178458\n",
       "Lasso                 0.810262  4.152624  3.253018\n",
       "SVR                   0.774600  4.526088  3.429478\n",
       "Extra Tree            0.739850  4.862483  3.797376\n",
       "Decision Tree         0.738008  4.879668  3.778136\n",
       "ElasticNet            0.718953  5.054002  3.723071\n",
       "AdaBoost              0.665066  5.517286  4.012822"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_test(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "264cab97-9ce1-465d-9e06-b752dfb8d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f35e7ea-5977-4535-bc42-92c0b22d89f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(240,activation=\"relu\"))\n",
    "model.add(Dense(196,activation=\"relu\")) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(144,activation=\"relu\")) \n",
    "model.add(Dense(96,activation=\"relu\"))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(32,activation=\"relu\")) \n",
    "model.add(Dense(16,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(8,activation=\"relu\"))\n",
    "model.add(Dense(4,activation=\"relu\"))\n",
    "model.add(Dense(1)) \n",
    "model.compile(loss=\"mse\", optimizer=\"adam\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c8b0d95-ea9e-4662-a7dc-d77b14f0e982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1100.9257 - val_loss: 1092.1658\n",
      "Epoch 2/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1015.3170 - val_loss: 935.8279\n",
      "Epoch 3/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 828.1753 - val_loss: 598.2991\n",
      "Epoch 4/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 457.9613 - val_loss: 196.5508\n",
      "Epoch 5/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158.7613 - val_loss: 82.9201\n",
      "Epoch 6/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.3336 - val_loss: 55.7796\n",
      "Epoch 7/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25.8819 - val_loss: 38.6580\n",
      "Epoch 8/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22.4894 - val_loss: 17.5640\n",
      "Epoch 9/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.3554 - val_loss: 19.3309\n",
      "Epoch 10/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.9269 - val_loss: 17.4019\n",
      "Epoch 11/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.2187 - val_loss: 16.5696\n",
      "Epoch 12/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.3008 - val_loss: 15.5648\n",
      "Epoch 13/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.1230 - val_loss: 15.4896\n",
      "Epoch 14/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.0928 - val_loss: 15.7930\n",
      "Epoch 15/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.6607 - val_loss: 15.0535\n",
      "Epoch 16/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.7242 - val_loss: 15.6928\n",
      "Epoch 17/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.1602 - val_loss: 15.4373\n",
      "Epoch 18/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.5770 - val_loss: 15.3486\n",
      "Epoch 19/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.9901 - val_loss: 16.3724\n",
      "Epoch 20/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.8321 - val_loss: 17.7118\n",
      "Epoch 21/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.3068 - val_loss: 15.9503\n",
      "Epoch 22/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.5350 - val_loss: 15.3997\n",
      "Epoch 23/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.5226 - val_loss: 15.6033\n",
      "Epoch 24/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.3262 - val_loss: 15.1500\n",
      "Epoch 25/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.2391 - val_loss: 15.4382\n",
      "Epoch 26/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.3863 - val_loss: 15.0701\n",
      "Epoch 27/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15.9118 - val_loss: 15.1235\n",
      "Epoch 28/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.0952 - val_loss: 15.1998\n",
      "Epoch 29/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.2911 - val_loss: 14.9602\n",
      "Epoch 30/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.0701 - val_loss: 14.8425\n",
      "Epoch 31/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.9816 - val_loss: 15.3443\n",
      "Epoch 32/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.1269 - val_loss: 15.3490\n",
      "Epoch 33/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15.0948 - val_loss: 15.2092\n",
      "Epoch 34/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15.4382 - val_loss: 14.9943\n",
      "Epoch 35/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.8165 - val_loss: 15.5794\n",
      "Epoch 36/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.7915 - val_loss: 15.9023\n",
      "Epoch 37/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.4009 - val_loss: 16.2134\n",
      "Epoch 38/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.2309 - val_loss: 15.7850\n",
      "Epoch 39/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.7866 - val_loss: 15.5520\n",
      "Epoch 40/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.6312 - val_loss: 15.5926\n",
      "Epoch 41/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.7933 - val_loss: 15.4322\n",
      "Epoch 42/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.5878 - val_loss: 15.9252\n",
      "Epoch 43/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.6819 - val_loss: 15.6245\n",
      "Epoch 44/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.4215 - val_loss: 15.6199\n",
      "Epoch 45/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.6909 - val_loss: 15.2873\n",
      "Epoch 46/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.5671 - val_loss: 15.4810\n",
      "Epoch 47/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.0787 - val_loss: 16.6328\n",
      "Epoch 48/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.1437 - val_loss: 15.7498\n",
      "Epoch 49/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.9394 - val_loss: 16.2992\n",
      "Epoch 50/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.1316 - val_loss: 16.0581\n",
      "Epoch 51/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.3719 - val_loss: 16.1802\n",
      "Epoch 52/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.1447 - val_loss: 16.0916\n",
      "Epoch 53/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.9700 - val_loss: 15.6830\n",
      "Epoch 54/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.9125 - val_loss: 15.6719\n",
      "Epoch 55/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.3592 - val_loss: 16.1239\n",
      "Epoch 56/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.0715 - val_loss: 16.0466\n",
      "Epoch 57/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.8767 - val_loss: 15.0582\n",
      "Epoch 58/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.4608 - val_loss: 16.0613\n",
      "Epoch 59/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.3990 - val_loss: 15.8248\n",
      "Epoch 60/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.2580 - val_loss: 16.1404\n",
      "Epoch 61/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.4392 - val_loss: 16.2149\n",
      "Epoch 62/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.5056 - val_loss: 15.5776\n",
      "Epoch 63/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.1119 - val_loss: 16.2054\n",
      "Epoch 64/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.2146 - val_loss: 16.0104\n",
      "Epoch 65/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.1657 - val_loss: 15.6386\n",
      "Epoch 66/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.9714 - val_loss: 15.7393\n",
      "Epoch 67/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.7832 - val_loss: 16.0509\n",
      "Epoch 68/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.4027 - val_loss: 15.5064\n",
      "Epoch 69/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.6813 - val_loss: 15.8577\n",
      "Epoch 70/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.8543 - val_loss: 16.3392\n",
      "Epoch 71/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.9010 - val_loss: 15.9113\n",
      "Epoch 72/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.9596 - val_loss: 16.1297\n",
      "Epoch 73/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.2268 - val_loss: 16.0250\n",
      "Epoch 74/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.9367 - val_loss: 16.9240\n",
      "Epoch 75/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.9035 - val_loss: 17.4238\n",
      "Epoch 76/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.2169 - val_loss: 16.5563\n",
      "Epoch 77/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.9998 - val_loss: 17.0853\n",
      "Epoch 78/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.6446 - val_loss: 16.0446\n",
      "Epoch 79/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.4673 - val_loss: 16.2198\n",
      "Epoch 80/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.6929 - val_loss: 16.9331\n",
      "Epoch 81/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.7726 - val_loss: 16.3213\n",
      "Epoch 82/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.5796 - val_loss: 15.8296\n",
      "Epoch 83/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.7356 - val_loss: 16.4493\n",
      "Epoch 84/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.7897 - val_loss: 16.3040\n",
      "Epoch 85/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.4246 - val_loss: 16.7087\n",
      "Epoch 86/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.4833 - val_loss: 16.3660\n",
      "Epoch 87/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.5190 - val_loss: 16.1146\n",
      "Epoch 88/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.2582 - val_loss: 16.7562\n",
      "Epoch 89/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.3349 - val_loss: 17.0049\n",
      "Epoch 90/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.7207 - val_loss: 17.3952\n",
      "Epoch 91/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.3855 - val_loss: 16.3612\n",
      "Epoch 92/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.2602 - val_loss: 16.0306\n",
      "Epoch 93/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.3568 - val_loss: 16.8221\n",
      "Epoch 94/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.5639 - val_loss: 16.3300\n",
      "Epoch 95/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.0926 - val_loss: 17.2791\n",
      "Epoch 96/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.4716 - val_loss: 16.3739\n",
      "Epoch 97/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.6244 - val_loss: 16.8059\n",
      "Epoch 98/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.7614 - val_loss: 16.8066\n",
      "Epoch 99/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.8990 - val_loss: 16.4684\n",
      "Epoch 100/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.0602 - val_loss: 16.9751\n",
      "Epoch 101/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.3156 - val_loss: 16.9027\n",
      "Epoch 102/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.9130 - val_loss: 16.4821\n",
      "Epoch 103/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.2683 - val_loss: 16.5981\n",
      "Epoch 104/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.2293 - val_loss: 16.4139\n",
      "Epoch 105/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.7150 - val_loss: 16.4264\n",
      "Epoch 106/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.9173 - val_loss: 17.0232\n",
      "Epoch 107/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.5153 - val_loss: 17.1727\n",
      "Epoch 108/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.0820 - val_loss: 16.7828\n",
      "Epoch 109/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.4516 - val_loss: 17.2962\n",
      "Epoch 110/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.3875 - val_loss: 16.5584\n",
      "Epoch 111/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.4968 - val_loss: 16.9389\n",
      "Epoch 112/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.7684 - val_loss: 16.7978\n",
      "Epoch 113/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.3491 - val_loss: 17.4223\n",
      "Epoch 114/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.9851 - val_loss: 16.5817\n",
      "Epoch 115/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.1287 - val_loss: 17.0607\n",
      "Epoch 116/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.7215 - val_loss: 16.6324\n",
      "Epoch 117/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.2980 - val_loss: 17.0173\n",
      "Epoch 118/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.8362 - val_loss: 16.5613\n",
      "Epoch 119/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.6627 - val_loss: 17.4236\n",
      "Epoch 120/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.2508 - val_loss: 17.0911\n",
      "Epoch 121/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.5468 - val_loss: 17.3787\n",
      "Epoch 122/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.9582 - val_loss: 17.0958\n",
      "Epoch 123/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.3502 - val_loss: 17.6246\n",
      "Epoch 124/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.3206 - val_loss: 18.8368\n",
      "Epoch 125/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.1446 - val_loss: 20.3083\n",
      "Epoch 126/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.3122 - val_loss: 17.9033\n",
      "Epoch 127/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.4902 - val_loss: 17.6234\n",
      "Epoch 128/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.0794 - val_loss: 17.3494\n",
      "Epoch 129/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.7807 - val_loss: 17.7939\n",
      "Epoch 130/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.9004 - val_loss: 17.3346\n",
      "Epoch 131/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.7151 - val_loss: 18.2539\n",
      "Epoch 132/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.3505 - val_loss: 17.1410\n",
      "Epoch 133/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.2164 - val_loss: 17.5194\n",
      "Epoch 134/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.9968 - val_loss: 17.0069\n",
      "Epoch 135/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.0115 - val_loss: 16.9200\n",
      "Epoch 136/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8279 - val_loss: 17.8595\n",
      "Epoch 137/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8810 - val_loss: 17.6356\n",
      "Epoch 138/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.1017 - val_loss: 17.7563\n",
      "Epoch 139/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.8525 - val_loss: 17.7121\n",
      "Epoch 140/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.9205 - val_loss: 17.7865\n",
      "Epoch 141/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.9817 - val_loss: 17.3102\n",
      "Epoch 142/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.6997 - val_loss: 17.4999\n",
      "Epoch 143/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.6373 - val_loss: 17.3558\n",
      "Epoch 144/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.7571 - val_loss: 17.1891\n",
      "Epoch 145/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8925 - val_loss: 17.4591\n",
      "Epoch 146/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.6574 - val_loss: 17.4594\n",
      "Epoch 147/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8752 - val_loss: 17.3145\n",
      "Epoch 148/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.5305 - val_loss: 17.4394\n",
      "Epoch 149/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.7423 - val_loss: 17.0435\n",
      "Epoch 150/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8285 - val_loss: 18.0636\n",
      "Epoch 151/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.5177 - val_loss: 17.3341\n",
      "Epoch 152/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8598 - val_loss: 18.1473\n",
      "Epoch 153/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.0714 - val_loss: 17.9700\n",
      "Epoch 154/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.1874 - val_loss: 17.6541\n",
      "Epoch 155/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.4016 - val_loss: 17.6307\n",
      "Epoch 156/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3762 - val_loss: 17.6882\n",
      "Epoch 157/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2922 - val_loss: 18.0708\n",
      "Epoch 158/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.6554 - val_loss: 17.2558\n",
      "Epoch 159/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2204 - val_loss: 17.2513\n",
      "Epoch 160/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.4803 - val_loss: 17.8209\n",
      "Epoch 161/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8888 - val_loss: 17.3540\n",
      "Epoch 162/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.6501 - val_loss: 18.5641\n",
      "Epoch 163/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.0573 - val_loss: 18.7306\n",
      "Epoch 164/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.7918 - val_loss: 18.0176\n",
      "Epoch 165/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.4081 - val_loss: 17.2210\n",
      "Epoch 166/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.5026 - val_loss: 17.8695\n",
      "Epoch 167/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3964 - val_loss: 17.5770\n",
      "Epoch 168/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.4770 - val_loss: 17.6449\n",
      "Epoch 169/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.5236 - val_loss: 17.1265\n",
      "Epoch 170/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.9901 - val_loss: 17.7230\n",
      "Epoch 171/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3292 - val_loss: 17.7490\n",
      "Epoch 172/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2838 - val_loss: 17.4115\n",
      "Epoch 173/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.4500 - val_loss: 17.7420\n",
      "Epoch 174/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.5427 - val_loss: 17.2460\n",
      "Epoch 175/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.4492 - val_loss: 17.9651\n",
      "Epoch 176/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.1254 - val_loss: 17.6563\n",
      "Epoch 177/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2767 - val_loss: 17.7240\n",
      "Epoch 178/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2270 - val_loss: 17.6492\n",
      "Epoch 179/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3216 - val_loss: 18.0735\n",
      "Epoch 180/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0906 - val_loss: 17.3158\n",
      "Epoch 181/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8075 - val_loss: 18.9233\n",
      "Epoch 182/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.9451 - val_loss: 18.2527\n",
      "Epoch 183/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0273 - val_loss: 17.5959\n",
      "Epoch 184/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.4678 - val_loss: 17.9762\n",
      "Epoch 185/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2084 - val_loss: 17.5884\n",
      "Epoch 186/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.9308 - val_loss: 17.6201\n",
      "Epoch 187/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.1269 - val_loss: 18.3084\n",
      "Epoch 188/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0204 - val_loss: 17.8501\n",
      "Epoch 189/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.9797 - val_loss: 17.7612\n",
      "Epoch 190/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.7077 - val_loss: 18.2446\n",
      "Epoch 191/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7306 - val_loss: 17.9763\n",
      "Epoch 192/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0147 - val_loss: 17.0760\n",
      "Epoch 193/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3634 - val_loss: 17.9834\n",
      "Epoch 194/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2534 - val_loss: 17.8331\n",
      "Epoch 195/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0498 - val_loss: 18.3825\n",
      "Epoch 196/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6364 - val_loss: 17.9274\n",
      "Epoch 197/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8200 - val_loss: 18.6037\n",
      "Epoch 198/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0239 - val_loss: 18.0398\n",
      "Epoch 199/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.9624 - val_loss: 18.4139\n",
      "Epoch 200/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7298 - val_loss: 17.9751\n",
      "Epoch 201/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8961 - val_loss: 17.4270\n",
      "Epoch 202/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.1663 - val_loss: 18.2034\n",
      "Epoch 203/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6609 - val_loss: 17.9322\n",
      "Epoch 204/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8938 - val_loss: 17.4577\n",
      "Epoch 205/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5326 - val_loss: 18.7629\n",
      "Epoch 206/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.4708 - val_loss: 18.1889\n",
      "Epoch 207/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2788 - val_loss: 18.3700\n",
      "Epoch 208/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.9095 - val_loss: 18.3842\n",
      "Epoch 209/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0218 - val_loss: 18.7399\n",
      "Epoch 210/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4924 - val_loss: 17.5381\n",
      "Epoch 211/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5861 - val_loss: 18.7308\n",
      "Epoch 212/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6602 - val_loss: 18.4192\n",
      "Epoch 213/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6534 - val_loss: 17.8457\n",
      "Epoch 214/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0191 - val_loss: 18.3995\n",
      "Epoch 215/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5464 - val_loss: 18.2070\n",
      "Epoch 216/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4649 - val_loss: 17.8649\n",
      "Epoch 217/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3277 - val_loss: 18.2007\n",
      "Epoch 218/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7938 - val_loss: 17.9105\n",
      "Epoch 219/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7161 - val_loss: 18.4566\n",
      "Epoch 220/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6331 - val_loss: 17.4794\n",
      "Epoch 221/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8915 - val_loss: 18.1290\n",
      "Epoch 222/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3928 - val_loss: 18.2576\n",
      "Epoch 223/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.5528 - val_loss: 18.1926\n",
      "Epoch 224/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6260 - val_loss: 18.7016\n",
      "Epoch 225/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.1585 - val_loss: 18.2265\n",
      "Epoch 226/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8535 - val_loss: 17.8434\n",
      "Epoch 227/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4877 - val_loss: 17.6674\n",
      "Epoch 228/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7377 - val_loss: 17.9996\n",
      "Epoch 229/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7878 - val_loss: 17.7090\n",
      "Epoch 230/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3991 - val_loss: 17.9348\n",
      "Epoch 231/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5048 - val_loss: 17.8237\n",
      "Epoch 232/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0029 - val_loss: 18.0087\n",
      "Epoch 233/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7406 - val_loss: 18.1434\n",
      "Epoch 234/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4830 - val_loss: 18.4892\n",
      "Epoch 235/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4132 - val_loss: 19.0283\n",
      "Epoch 236/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8345 - val_loss: 18.6505\n",
      "Epoch 237/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3621 - val_loss: 18.3634\n",
      "Epoch 238/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2039 - val_loss: 18.5756\n",
      "Epoch 239/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0415 - val_loss: 18.3584\n",
      "Epoch 240/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3043 - val_loss: 18.2672\n",
      "Epoch 241/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4340 - val_loss: 18.3921\n",
      "Epoch 242/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2168 - val_loss: 17.9843\n",
      "Epoch 243/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2591 - val_loss: 18.7305\n",
      "Epoch 244/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2751 - val_loss: 18.8419\n",
      "Epoch 245/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5960 - val_loss: 18.7863\n",
      "Epoch 246/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5037 - val_loss: 18.4736\n",
      "Epoch 247/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5577 - val_loss: 18.4722\n",
      "Epoch 248/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1276 - val_loss: 18.2439\n",
      "Epoch 249/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4024 - val_loss: 17.9392\n",
      "Epoch 250/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4027 - val_loss: 18.0595\n",
      "Epoch 251/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2394 - val_loss: 18.0980\n",
      "Epoch 252/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1022 - val_loss: 18.8661\n",
      "Epoch 253/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4763 - val_loss: 18.3983\n",
      "Epoch 254/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1969 - val_loss: 18.4495\n",
      "Epoch 255/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5397 - val_loss: 18.1771\n",
      "Epoch 256/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5000 - val_loss: 18.5140\n",
      "Epoch 257/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0367 - val_loss: 18.3331\n",
      "Epoch 258/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4606 - val_loss: 18.8276\n",
      "Epoch 259/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2085 - val_loss: 18.3164\n",
      "Epoch 260/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9621 - val_loss: 18.1451\n",
      "Epoch 261/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2737 - val_loss: 18.2116\n",
      "Epoch 262/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0438 - val_loss: 18.1268\n",
      "Epoch 263/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7286 - val_loss: 18.5428\n",
      "Epoch 264/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0458 - val_loss: 18.2322\n",
      "Epoch 265/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2335 - val_loss: 18.4439\n",
      "Epoch 266/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0541 - val_loss: 18.0406\n",
      "Epoch 267/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8313 - val_loss: 18.5174\n",
      "Epoch 268/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9509 - val_loss: 18.0737\n",
      "Epoch 269/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0157 - val_loss: 18.2786\n",
      "Epoch 270/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1813 - val_loss: 18.5686\n",
      "Epoch 271/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8242 - val_loss: 18.3086\n",
      "Epoch 272/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1183 - val_loss: 18.1027\n",
      "Epoch 273/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1850 - val_loss: 18.6495\n",
      "Epoch 274/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2102 - val_loss: 18.4494\n",
      "Epoch 275/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2773 - val_loss: 19.1198\n",
      "Epoch 276/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7699 - val_loss: 18.8699\n",
      "Epoch 277/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1057 - val_loss: 18.1851\n",
      "Epoch 278/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3710 - val_loss: 18.2100\n",
      "Epoch 279/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1633 - val_loss: 18.3987\n",
      "Epoch 280/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2003 - val_loss: 18.7527\n",
      "Epoch 281/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0983 - val_loss: 18.9161\n",
      "Epoch 282/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0891 - val_loss: 18.1511\n",
      "Epoch 283/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3348 - val_loss: 18.7564\n",
      "Epoch 284/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.4559 - val_loss: 18.1744\n",
      "Epoch 285/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9495 - val_loss: 17.9677\n",
      "Epoch 286/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8263 - val_loss: 18.0529\n",
      "Epoch 287/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2834 - val_loss: 18.1534\n",
      "Epoch 288/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.7863 - val_loss: 18.7271\n",
      "Epoch 289/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2727 - val_loss: 18.1025\n",
      "Epoch 290/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0968 - val_loss: 18.1687\n",
      "Epoch 291/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0975 - val_loss: 17.8198\n",
      "Epoch 292/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0960 - val_loss: 18.4488\n",
      "Epoch 293/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1464 - val_loss: 17.8015\n",
      "Epoch 294/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1904 - val_loss: 18.2498\n",
      "Epoch 295/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2068 - val_loss: 18.3620\n",
      "Epoch 296/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0884 - val_loss: 18.4480\n",
      "Epoch 297/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8227 - val_loss: 18.5903\n",
      "Epoch 298/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.9699 - val_loss: 18.7674\n",
      "Epoch 299/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8651 - val_loss: 19.0265\n",
      "Epoch 300/300\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0721 - val_loss: 18.4826\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train ,validation_data=(x_test,y_test), batch_size=128, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59d3ead4-70fe-4cb6-8f1c-18d109b0e506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a0d6ba8-69af-486d-ac57-5aa27e960458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.299139198529712"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(tahmin,y_test)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b267c4c-cf01-43cc-b652-b4a9c4ebdc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7304921353124149"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(tahmin,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3ee4de1-51cf-473b-ae60-e1037893c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f=pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "667ad4e3-42cc-424e-b259-d9f03f7b8b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_f.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce70e08-dd39-45d5-bc8c-ab610cd496ae",
   "metadata": {},
   "source": [
    "!Regression da kuşakları vermeyince yaş tahmini scoru eksilerde çıkyor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ea90a1-b8ea-406b-b6f1-32ba51f05fd7",
   "metadata": {},
   "source": [
    "#### Classification ile Kuşak tahmini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95b95e4e-2735-4fe2-bd7b-29c3c4013db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "      <th>orientation</th>\n",
       "      <th>drugs</th>\n",
       "      <th>drinks</th>\n",
       "      <th>body_type</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>Kusak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>m</td>\n",
       "      <td>yes</td>\n",
       "      <td>straight</td>\n",
       "      <td>never</td>\n",
       "      <td>socially</td>\n",
       "      <td>weight</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>often</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>no</td>\n",
       "      <td>socially</td>\n",
       "      <td>thin</td>\n",
       "      <td>No</td>\n",
       "      <td>cats</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>no</td>\n",
       "      <td>socially</td>\n",
       "      <td>thin</td>\n",
       "      <td>No</td>\n",
       "      <td>cats</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>never</td>\n",
       "      <td>socially</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509</th>\n",
       "      <td>28.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>never</td>\n",
       "      <td>socially</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510</th>\n",
       "      <td>31.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>m</td>\n",
       "      <td>yes</td>\n",
       "      <td>gay</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>socially</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9511</th>\n",
       "      <td>34.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>yes</td>\n",
       "      <td>gay</td>\n",
       "      <td>no</td>\n",
       "      <td>socially</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9512</th>\n",
       "      <td>29.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>gay</td>\n",
       "      <td>never</td>\n",
       "      <td>rarely</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9513</th>\n",
       "      <td>49.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>never</td>\n",
       "      <td>rarely</td>\n",
       "      <td>overweight</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9514 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  height sex smokes orientation      drugs    drinks   body_type  \\\n",
       "0     22.0    75.0   m    yes    straight      never  socially      weight   \n",
       "1     35.0    70.0   m     no    straight  sometimes     often         fit   \n",
       "2     38.0    68.0   m     no    straight         no  socially        thin   \n",
       "3     23.0    71.0   m     no    straight         no  socially        thin   \n",
       "4     29.0    66.0   m     no    straight      never  socially         fit   \n",
       "...    ...     ...  ..    ...         ...        ...       ...         ...   \n",
       "9509  28.0    73.0   m     no    straight      never  socially         fit   \n",
       "9510  31.0    72.0   m    yes         gay  sometimes  socially         fit   \n",
       "9511  34.0    71.0   m    yes         gay         no  socially         fit   \n",
       "9512  29.0    70.0   m     no         gay      never    rarely         fit   \n",
       "9513  49.0    64.0   f     no    straight      never    rarely  overweight   \n",
       "\n",
       "     offspring  pets  Kusak  \n",
       "0           No   all      1  \n",
       "1           No   all      2  \n",
       "2           No  cats      2  \n",
       "3           No  cats      1  \n",
       "4           No   all      1  \n",
       "...        ...   ...    ...  \n",
       "9509        No   all      1  \n",
       "9510        No   not      1  \n",
       "9511        No   all      2  \n",
       "9512        No   all      1  \n",
       "9513        No   all      3  \n",
       "\n",
       "[9514 rows x 11 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "caca9e8f-5b3e-4640-84e6-e589cab4ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(\"Kusak\",axis=1)\n",
    "y=df[\"Kusak\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bae3f474-e7fc-4fb1-ab2b-4dea6dcf03e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       2\n",
       "2       2\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "9509    1\n",
       "9510    1\n",
       "9511    2\n",
       "9512    1\n",
       "9513    3\n",
       "Name: Kusak, Length: 9514, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd3abef9-f94f-44ec-a666-372c9ff31c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "      <th>orientation</th>\n",
       "      <th>drugs</th>\n",
       "      <th>drinks</th>\n",
       "      <th>body_type</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>m</td>\n",
       "      <td>yes</td>\n",
       "      <td>straight</td>\n",
       "      <td>never</td>\n",
       "      <td>socially</td>\n",
       "      <td>weight</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>often</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>no</td>\n",
       "      <td>socially</td>\n",
       "      <td>thin</td>\n",
       "      <td>No</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>no</td>\n",
       "      <td>socially</td>\n",
       "      <td>thin</td>\n",
       "      <td>No</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>never</td>\n",
       "      <td>socially</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509</th>\n",
       "      <td>28.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>never</td>\n",
       "      <td>socially</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510</th>\n",
       "      <td>31.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>m</td>\n",
       "      <td>yes</td>\n",
       "      <td>gay</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>socially</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9511</th>\n",
       "      <td>34.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>yes</td>\n",
       "      <td>gay</td>\n",
       "      <td>no</td>\n",
       "      <td>socially</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9512</th>\n",
       "      <td>29.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "      <td>gay</td>\n",
       "      <td>never</td>\n",
       "      <td>rarely</td>\n",
       "      <td>fit</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9513</th>\n",
       "      <td>49.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>never</td>\n",
       "      <td>rarely</td>\n",
       "      <td>overweight</td>\n",
       "      <td>No</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9514 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  height sex smokes orientation      drugs    drinks   body_type  \\\n",
       "0     22.0    75.0   m    yes    straight      never  socially      weight   \n",
       "1     35.0    70.0   m     no    straight  sometimes     often         fit   \n",
       "2     38.0    68.0   m     no    straight         no  socially        thin   \n",
       "3     23.0    71.0   m     no    straight         no  socially        thin   \n",
       "4     29.0    66.0   m     no    straight      never  socially         fit   \n",
       "...    ...     ...  ..    ...         ...        ...       ...         ...   \n",
       "9509  28.0    73.0   m     no    straight      never  socially         fit   \n",
       "9510  31.0    72.0   m    yes         gay  sometimes  socially         fit   \n",
       "9511  34.0    71.0   m    yes         gay         no  socially         fit   \n",
       "9512  29.0    70.0   m     no         gay      never    rarely         fit   \n",
       "9513  49.0    64.0   f     no    straight      never    rarely  overweight   \n",
       "\n",
       "     offspring  pets  \n",
       "0           No   all  \n",
       "1           No   all  \n",
       "2           No  cats  \n",
       "3           No  cats  \n",
       "4           No   all  \n",
       "...        ...   ...  \n",
       "9509        No   all  \n",
       "9510        No   not  \n",
       "9511        No   all  \n",
       "9512        No   all  \n",
       "9513        No   all  \n",
       "\n",
       "[9514 rows x 10 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c383f46c-27e0-4cf2-b4b1-a42b4acd2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.get_dummies(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1744900d-2017-476c-8cd3-7c4ee7e63775",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scale(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e884af4-1dd3-4295-8be1-845fdaf358c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "# y= label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee4e9259-deeb-455f-9cd9-b524ccb5b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6486476b-53b8-44a7-8c01-5afe2c947744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7563    1\n",
       "6125    2\n",
       "1941    1\n",
       "4750    1\n",
       "3315    1\n",
       "       ..\n",
       "5734    2\n",
       "5191    1\n",
       "5390    3\n",
       "860     2\n",
       "7270    2\n",
       "Name: Kusak, Length: 7611, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19fd4b3c-d6aa-4b62-a584-a5e8ce38e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(240,activation=\"relu\")) \n",
    "model.add(Dense(196,activation=\"relu\")) \n",
    "model.add(Dense(144,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(112,activation=\"relu\"))\n",
    "model.add(Dense(96,activation=\"relu\"))\n",
    "model.add(Dense(72,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(60,activation=\"relu\"))\n",
    "model.add(Dense(48,activation=\"relu\"))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(18,activation=\"relu\"))\n",
    "model.add(Dense(6,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\")) \n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6b2f0bbc-4b70-482e-b99f-507fdf0fe7ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.5403 - loss: -16.4074 - val_accuracy: 0.6277 - val_loss: -715.4804\n",
      "Epoch 2/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6418 - loss: -1176.2195 - val_accuracy: 0.6277 - val_loss: -10857.3018\n",
      "Epoch 3/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6297 - loss: -11005.8174 - val_accuracy: 0.6277 - val_loss: -35201.0625\n",
      "Epoch 4/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6295 - loss: -44853.1719 - val_accuracy: 0.6277 - val_loss: -98721.5156\n",
      "Epoch 5/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6271 - loss: -121924.3672 - val_accuracy: 0.6277 - val_loss: -289016.9688\n",
      "Epoch 6/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6409 - loss: -254486.5156 - val_accuracy: 0.6277 - val_loss: -440343.5312\n",
      "Epoch 7/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6449 - loss: -470689.5312 - val_accuracy: 0.6277 - val_loss: -737345.7500\n",
      "Epoch 8/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6355 - loss: -797468.0625 - val_accuracy: 0.6277 - val_loss: -1206862.8750\n",
      "Epoch 9/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6269 - loss: -1251039.3750 - val_accuracy: 0.6277 - val_loss: -1818968.1250\n",
      "Epoch 10/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6365 - loss: -1788305.8750 - val_accuracy: 0.6277 - val_loss: -2434222.0000\n",
      "Epoch 11/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6384 - loss: -2465039.0000 - val_accuracy: 0.6277 - val_loss: -3503293.2500\n",
      "Epoch 12/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6329 - loss: -3309853.2500 - val_accuracy: 0.6277 - val_loss: -3891651.7500\n",
      "Epoch 13/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6285 - loss: -4492842.5000 - val_accuracy: 0.6277 - val_loss: -6293386.5000\n",
      "Epoch 14/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6252 - loss: -5740204.5000 - val_accuracy: 0.6277 - val_loss: -7173953.5000\n",
      "Epoch 15/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6346 - loss: -7152037.5000 - val_accuracy: 0.6277 - val_loss: -9116246.0000\n",
      "Epoch 16/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6330 - loss: -8911291.0000 - val_accuracy: 0.6277 - val_loss: -11600328.0000\n",
      "Epoch 17/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6418 - loss: -10725506.0000 - val_accuracy: 0.6277 - val_loss: -14240396.0000\n",
      "Epoch 18/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6416 - loss: -12856158.0000 - val_accuracy: 0.6277 - val_loss: -14760725.0000\n",
      "Epoch 19/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6309 - loss: -15656964.0000 - val_accuracy: 0.6277 - val_loss: -22834430.0000\n",
      "Epoch 20/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6371 - loss: -18375806.0000 - val_accuracy: 0.6277 - val_loss: -23122186.0000\n",
      "Epoch 21/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6316 - loss: -21939708.0000 - val_accuracy: 0.6277 - val_loss: -23980450.0000\n",
      "Epoch 22/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6276 - loss: -25628490.0000 - val_accuracy: 0.6277 - val_loss: -30518708.0000\n",
      "Epoch 23/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6260 - loss: -29694146.0000 - val_accuracy: 0.6277 - val_loss: -39949776.0000\n",
      "Epoch 24/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6469 - loss: -32701844.0000 - val_accuracy: 0.6277 - val_loss: -46689608.0000\n",
      "Epoch 25/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6416 - loss: -37592988.0000 - val_accuracy: 0.6277 - val_loss: -53451876.0000\n",
      "Epoch 26/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6294 - loss: -43974000.0000 - val_accuracy: 0.6277 - val_loss: -57408064.0000\n",
      "Epoch 27/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6348 - loss: -49540112.0000 - val_accuracy: 0.6277 - val_loss: -56636196.0000\n",
      "Epoch 28/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6466 - loss: -54968544.0000 - val_accuracy: 0.6277 - val_loss: -65998868.0000\n",
      "Epoch 29/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6283 - loss: -63826324.0000 - val_accuracy: 0.6277 - val_loss: -70276008.0000\n",
      "Epoch 30/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6267 - loss: -69919192.0000 - val_accuracy: 0.6277 - val_loss: -89808240.0000\n",
      "Epoch 31/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6275 - loss: -77773152.0000 - val_accuracy: 0.6277 - val_loss: -94406784.0000\n",
      "Epoch 32/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6274 - loss: -88397072.0000 - val_accuracy: 0.6277 - val_loss: -106033160.0000\n",
      "Epoch 33/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6360 - loss: -94692840.0000 - val_accuracy: 0.6277 - val_loss: -103304024.0000\n",
      "Epoch 34/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6351 - loss: -102290504.0000 - val_accuracy: 0.6277 - val_loss: -130500440.0000\n",
      "Epoch 35/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6395 - loss: -115295520.0000 - val_accuracy: 0.6277 - val_loss: -119223176.0000\n",
      "Epoch 36/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6438 - loss: -124718296.0000 - val_accuracy: 0.6277 - val_loss: -141550128.0000\n",
      "Epoch 37/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6287 - loss: -141153824.0000 - val_accuracy: 0.6277 - val_loss: -171293824.0000\n",
      "Epoch 38/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6431 - loss: -151497072.0000 - val_accuracy: 0.6277 - val_loss: -184283776.0000\n",
      "Epoch 39/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6354 - loss: -165143376.0000 - val_accuracy: 0.6277 - val_loss: -197605696.0000\n",
      "Epoch 40/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6341 - loss: -179879632.0000 - val_accuracy: 0.6277 - val_loss: -213514304.0000\n",
      "Epoch 41/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6363 - loss: -192702848.0000 - val_accuracy: 0.6277 - val_loss: -212039024.0000\n",
      "Epoch 42/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6272 - loss: -211525840.0000 - val_accuracy: 0.6277 - val_loss: -250018320.0000\n",
      "Epoch 43/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6364 - loss: -226276784.0000 - val_accuracy: 0.6277 - val_loss: -280270208.0000\n",
      "Epoch 44/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6257 - loss: -250260880.0000 - val_accuracy: 0.6277 - val_loss: -267537744.0000\n",
      "Epoch 45/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6388 - loss: -263705184.0000 - val_accuracy: 0.6277 - val_loss: -320890016.0000\n",
      "Epoch 46/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6301 - loss: -287825952.0000 - val_accuracy: 0.6277 - val_loss: -342530752.0000\n",
      "Epoch 47/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6447 - loss: -299705024.0000 - val_accuracy: 0.6277 - val_loss: -344495808.0000\n",
      "Epoch 48/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6375 - loss: -330467296.0000 - val_accuracy: 0.6277 - val_loss: -380106016.0000\n",
      "Epoch 49/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6341 - loss: -349637664.0000 - val_accuracy: 0.6277 - val_loss: -412509696.0000\n",
      "Epoch 50/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: -377735584.0000 - val_accuracy: 0.6277 - val_loss: -448234656.0000\n",
      "Epoch 51/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6332 - loss: -404327424.0000 - val_accuracy: 0.6277 - val_loss: -472232352.0000\n",
      "Epoch 52/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6280 - loss: -431303424.0000 - val_accuracy: 0.6277 - val_loss: -488519040.0000\n",
      "Epoch 53/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6259 - loss: -462110176.0000 - val_accuracy: 0.6277 - val_loss: -561946624.0000\n",
      "Epoch 54/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6371 - loss: -488480832.0000 - val_accuracy: 0.6277 - val_loss: -596145344.0000\n",
      "Epoch 55/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6265 - loss: -520830304.0000 - val_accuracy: 0.6277 - val_loss: -622386176.0000\n",
      "Epoch 56/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6394 - loss: -543480384.0000 - val_accuracy: 0.6277 - val_loss: -592371968.0000\n",
      "Epoch 57/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6379 - loss: -573430848.0000 - val_accuracy: 0.6277 - val_loss: -709054912.0000\n",
      "Epoch 58/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6441 - loss: -608494464.0000 - val_accuracy: 0.6277 - val_loss: -766804864.0000\n",
      "Epoch 59/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6336 - loss: -652913216.0000 - val_accuracy: 0.6277 - val_loss: -752672064.0000\n",
      "Epoch 60/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6284 - loss: -707158400.0000 - val_accuracy: 0.6277 - val_loss: -768276416.0000\n",
      "Epoch 61/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6293 - loss: -748175552.0000 - val_accuracy: 0.6277 - val_loss: -839291456.0000\n",
      "Epoch 62/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6339 - loss: -772087616.0000 - val_accuracy: 0.6277 - val_loss: -850852928.0000\n",
      "Epoch 63/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6340 - loss: -829142016.0000 - val_accuracy: 0.6277 - val_loss: -906495232.0000\n",
      "Epoch 64/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6396 - loss: -860974592.0000 - val_accuracy: 0.6277 - val_loss: -1031463488.0000\n",
      "Epoch 65/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6357 - loss: -916043456.0000 - val_accuracy: 0.6277 - val_loss: -1035900032.0000\n",
      "Epoch 66/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6277 - loss: -974325504.0000 - val_accuracy: 0.6277 - val_loss: -1184760320.0000\n",
      "Epoch 67/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6377 - loss: -1009329280.0000 - val_accuracy: 0.6277 - val_loss: -1173128448.0000\n",
      "Epoch 68/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6379 - loss: -1057765888.0000 - val_accuracy: 0.6277 - val_loss: -1273928576.0000\n",
      "Epoch 69/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6406 - loss: -1110401024.0000 - val_accuracy: 0.6277 - val_loss: -1253094656.0000\n",
      "Epoch 70/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6335 - loss: -1188906752.0000 - val_accuracy: 0.6277 - val_loss: -1313664512.0000\n",
      "Epoch 71/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6394 - loss: -1222597248.0000 - val_accuracy: 0.6277 - val_loss: -1619449344.0000\n",
      "Epoch 72/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6436 - loss: -1259312000.0000 - val_accuracy: 0.6277 - val_loss: -1431181312.0000\n",
      "Epoch 73/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6415 - loss: -1347644928.0000 - val_accuracy: 0.6277 - val_loss: -1490621696.0000\n",
      "Epoch 74/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6473 - loss: -1395535872.0000 - val_accuracy: 0.6277 - val_loss: -1593276928.0000\n",
      "Epoch 75/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6380 - loss: -1468760448.0000 - val_accuracy: 0.6277 - val_loss: -1644819712.0000\n",
      "Epoch 76/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6445 - loss: -1537035904.0000 - val_accuracy: 0.6277 - val_loss: -1986129152.0000\n",
      "Epoch 77/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6469 - loss: -1589311488.0000 - val_accuracy: 0.6277 - val_loss: -1911832832.0000\n",
      "Epoch 78/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6393 - loss: -1668150016.0000 - val_accuracy: 0.6277 - val_loss: -1978499712.0000\n",
      "Epoch 79/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6376 - loss: -1783515520.0000 - val_accuracy: 0.6277 - val_loss: -2048830592.0000\n",
      "Epoch 80/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6352 - loss: -1860789376.0000 - val_accuracy: 0.6277 - val_loss: -2158200832.0000\n",
      "Epoch 81/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6369 - loss: -1945131648.0000 - val_accuracy: 0.6277 - val_loss: -2055153536.0000\n",
      "Epoch 82/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6366 - loss: -1991654528.0000 - val_accuracy: 0.6277 - val_loss: -2313132800.0000\n",
      "Epoch 83/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6348 - loss: -2092985984.0000 - val_accuracy: 0.6277 - val_loss: -2452211712.0000\n",
      "Epoch 84/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6371 - loss: -2177941248.0000 - val_accuracy: 0.6277 - val_loss: -2491034368.0000\n",
      "Epoch 85/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6338 - loss: -2260932608.0000 - val_accuracy: 0.6277 - val_loss: -2827265792.0000\n",
      "Epoch 86/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6397 - loss: -2355791872.0000 - val_accuracy: 0.6277 - val_loss: -2648461312.0000\n",
      "Epoch 87/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6431 - loss: -2412012288.0000 - val_accuracy: 0.6277 - val_loss: -2762561792.0000\n",
      "Epoch 88/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6330 - loss: -2580813824.0000 - val_accuracy: 0.6277 - val_loss: -3035593728.0000\n",
      "Epoch 89/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6332 - loss: -2687728896.0000 - val_accuracy: 0.6277 - val_loss: -3016413440.0000\n",
      "Epoch 90/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6331 - loss: -2797485312.0000 - val_accuracy: 0.6277 - val_loss: -3115726848.0000\n",
      "Epoch 91/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6339 - loss: -2916770048.0000 - val_accuracy: 0.6277 - val_loss: -3179371520.0000\n",
      "Epoch 92/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6346 - loss: -3037700352.0000 - val_accuracy: 0.6277 - val_loss: -3447698176.0000\n",
      "Epoch 93/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6273 - loss: -3169871360.0000 - val_accuracy: 0.6277 - val_loss: -3309118464.0000\n",
      "Epoch 94/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6316 - loss: -3252230144.0000 - val_accuracy: 0.6277 - val_loss: -3573956352.0000\n",
      "Epoch 95/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6322 - loss: -3416105472.0000 - val_accuracy: 0.6277 - val_loss: -3734471680.0000\n",
      "Epoch 96/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6361 - loss: -3534456320.0000 - val_accuracy: 0.6277 - val_loss: -4129676032.0000\n",
      "Epoch 97/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6319 - loss: -3598463232.0000 - val_accuracy: 0.6277 - val_loss: -3929037568.0000\n",
      "Epoch 98/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6301 - loss: -3745857024.0000 - val_accuracy: 0.6277 - val_loss: -4275713792.0000\n",
      "Epoch 99/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6400 - loss: -3786762240.0000 - val_accuracy: 0.6277 - val_loss: -4188742656.0000\n",
      "Epoch 100/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6454 - loss: -3991183616.0000 - val_accuracy: 0.6277 - val_loss: -4618338816.0000\n",
      "Epoch 101/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6381 - loss: -4143584256.0000 - val_accuracy: 0.6277 - val_loss: -4821779456.0000\n",
      "Epoch 102/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: -4399712768.0000 - val_accuracy: 0.6277 - val_loss: -4761847808.0000\n",
      "Epoch 103/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6341 - loss: -4455751168.0000 - val_accuracy: 0.6277 - val_loss: -5149082112.0000\n",
      "Epoch 104/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6445 - loss: -4512611328.0000 - val_accuracy: 0.6277 - val_loss: -5047906304.0000\n",
      "Epoch 105/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6374 - loss: -4698107904.0000 - val_accuracy: 0.6277 - val_loss: -5254468608.0000\n",
      "Epoch 106/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6397 - loss: -4816434176.0000 - val_accuracy: 0.6277 - val_loss: -6113397760.0000\n",
      "Epoch 107/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6327 - loss: -5049671680.0000 - val_accuracy: 0.6277 - val_loss: -5627826688.0000\n",
      "Epoch 108/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6397 - loss: -5180732416.0000 - val_accuracy: 0.6277 - val_loss: -6167919616.0000\n",
      "Epoch 109/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6289 - loss: -5385855488.0000 - val_accuracy: 0.6277 - val_loss: -6242662400.0000\n",
      "Epoch 110/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6412 - loss: -5523710464.0000 - val_accuracy: 0.6277 - val_loss: -6056795136.0000\n",
      "Epoch 111/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6457 - loss: -5642390528.0000 - val_accuracy: 0.6277 - val_loss: -6415762944.0000\n",
      "Epoch 112/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6240 - loss: -6086582784.0000 - val_accuracy: 0.6277 - val_loss: -6669910528.0000\n",
      "Epoch 113/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6363 - loss: -6219332096.0000 - val_accuracy: 0.6277 - val_loss: -6921543680.0000\n",
      "Epoch 114/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6340 - loss: -6375144448.0000 - val_accuracy: 0.6277 - val_loss: -7092789248.0000\n",
      "Epoch 115/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6360 - loss: -6421275136.0000 - val_accuracy: 0.6277 - val_loss: -7231617536.0000\n",
      "Epoch 116/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6408 - loss: -6718480896.0000 - val_accuracy: 0.6277 - val_loss: -7695841280.0000\n",
      "Epoch 117/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6303 - loss: -6939633152.0000 - val_accuracy: 0.6277 - val_loss: -7657239552.0000\n",
      "Epoch 118/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6348 - loss: -7272727040.0000 - val_accuracy: 0.6277 - val_loss: -7815870464.0000\n",
      "Epoch 119/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6345 - loss: -7409885696.0000 - val_accuracy: 0.6277 - val_loss: -8216967168.0000\n",
      "Epoch 120/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6276 - loss: -7653052416.0000 - val_accuracy: 0.6277 - val_loss: -8596450304.0000\n",
      "Epoch 121/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6396 - loss: -7700326912.0000 - val_accuracy: 0.6277 - val_loss: -8619531264.0000\n",
      "Epoch 122/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6419 - loss: -8050906624.0000 - val_accuracy: 0.6277 - val_loss: -8859749376.0000\n",
      "Epoch 123/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6405 - loss: -8117065216.0000 - val_accuracy: 0.6277 - val_loss: -9402540032.0000\n",
      "Epoch 124/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6354 - loss: -8429654016.0000 - val_accuracy: 0.6277 - val_loss: -9677008896.0000\n",
      "Epoch 125/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6351 - loss: -8887383040.0000 - val_accuracy: 0.6277 - val_loss: -10145800192.0000\n",
      "Epoch 126/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6312 - loss: -9158671360.0000 - val_accuracy: 0.6277 - val_loss: -10209347584.0000\n",
      "Epoch 127/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6384 - loss: -9110524928.0000 - val_accuracy: 0.6277 - val_loss: -10244427776.0000\n",
      "Epoch 128/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6327 - loss: -9538078720.0000 - val_accuracy: 0.6277 - val_loss: -10331384832.0000\n",
      "Epoch 129/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6320 - loss: -9848568832.0000 - val_accuracy: 0.6277 - val_loss: -11061616640.0000\n",
      "Epoch 130/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6334 - loss: -10125854720.0000 - val_accuracy: 0.6277 - val_loss: -11790531584.0000\n",
      "Epoch 131/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6362 - loss: -10210950144.0000 - val_accuracy: 0.6277 - val_loss: -11004400640.0000\n",
      "Epoch 132/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6238 - loss: -10821547008.0000 - val_accuracy: 0.6277 - val_loss: -12013074432.0000\n",
      "Epoch 133/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6301 - loss: -10981936128.0000 - val_accuracy: 0.6277 - val_loss: -11936642048.0000\n",
      "Epoch 134/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6366 - loss: -11086443520.0000 - val_accuracy: 0.6277 - val_loss: -12121112576.0000\n",
      "Epoch 135/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6384 - loss: -11527888896.0000 - val_accuracy: 0.6277 - val_loss: -13051065344.0000\n",
      "Epoch 136/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6373 - loss: -11738784768.0000 - val_accuracy: 0.6277 - val_loss: -12966194176.0000\n",
      "Epoch 137/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6327 - loss: -12242332672.0000 - val_accuracy: 0.6277 - val_loss: -14649923584.0000\n",
      "Epoch 138/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6389 - loss: -12288990208.0000 - val_accuracy: 0.6277 - val_loss: -13814496256.0000\n",
      "Epoch 139/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6424 - loss: -12615997440.0000 - val_accuracy: 0.6277 - val_loss: -13936209920.0000\n",
      "Epoch 140/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6405 - loss: -12806966272.0000 - val_accuracy: 0.6277 - val_loss: -13967987712.0000\n",
      "Epoch 141/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6289 - loss: -13523864576.0000 - val_accuracy: 0.6277 - val_loss: -14958448640.0000\n",
      "Epoch 142/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6474 - loss: -13490893824.0000 - val_accuracy: 0.6277 - val_loss: -14960036864.0000\n",
      "Epoch 143/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6355 - loss: -14098446336.0000 - val_accuracy: 0.6277 - val_loss: -15915765760.0000\n",
      "Epoch 144/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6338 - loss: -14420490240.0000 - val_accuracy: 0.6277 - val_loss: -15886972928.0000\n",
      "Epoch 145/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6327 - loss: -14881254400.0000 - val_accuracy: 0.6277 - val_loss: -15368713216.0000\n",
      "Epoch 146/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6421 - loss: -15122367488.0000 - val_accuracy: 0.6277 - val_loss: -18522742784.0000\n",
      "Epoch 147/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6380 - loss: -15518741504.0000 - val_accuracy: 0.6277 - val_loss: -17523013632.0000\n",
      "Epoch 148/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6395 - loss: -15813419008.0000 - val_accuracy: 0.6277 - val_loss: -17427994624.0000\n",
      "Epoch 149/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6334 - loss: -16593958912.0000 - val_accuracy: 0.6277 - val_loss: -18109747200.0000\n",
      "Epoch 150/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6246 - loss: -16813503488.0000 - val_accuracy: 0.6277 - val_loss: -18491037696.0000\n",
      "Epoch 151/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6455 - loss: -16718429184.0000 - val_accuracy: 0.6277 - val_loss: -18675789824.0000\n",
      "Epoch 152/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6354 - loss: -17778841600.0000 - val_accuracy: 0.6277 - val_loss: -19801430016.0000\n",
      "Epoch 153/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6299 - loss: -18053117952.0000 - val_accuracy: 0.6277 - val_loss: -20265697280.0000\n",
      "Epoch 154/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6351 - loss: -18319022080.0000 - val_accuracy: 0.6277 - val_loss: -19959332864.0000\n",
      "Epoch 155/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6379 - loss: -18825580544.0000 - val_accuracy: 0.6277 - val_loss: -21037361152.0000\n",
      "Epoch 156/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6351 - loss: -19290228736.0000 - val_accuracy: 0.6277 - val_loss: -21798252544.0000\n",
      "Epoch 157/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6230 - loss: -20276060160.0000 - val_accuracy: 0.6277 - val_loss: -22984257536.0000\n",
      "Epoch 158/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6353 - loss: -20073482240.0000 - val_accuracy: 0.6277 - val_loss: -23301486592.0000\n",
      "Epoch 159/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6399 - loss: -20418183168.0000 - val_accuracy: 0.6277 - val_loss: -23067058176.0000\n",
      "Epoch 160/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6302 - loss: -21456541696.0000 - val_accuracy: 0.6277 - val_loss: -22974009344.0000\n",
      "Epoch 161/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6420 - loss: -21143898112.0000 - val_accuracy: 0.6277 - val_loss: -23810709504.0000\n",
      "Epoch 162/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6325 - loss: -22060189696.0000 - val_accuracy: 0.6277 - val_loss: -23609114624.0000\n",
      "Epoch 163/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6425 - loss: -22434203648.0000 - val_accuracy: 0.6277 - val_loss: -24638908416.0000\n",
      "Epoch 164/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6367 - loss: -22893961216.0000 - val_accuracy: 0.6277 - val_loss: -27245932544.0000\n",
      "Epoch 165/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6341 - loss: -23473319936.0000 - val_accuracy: 0.6277 - val_loss: -26180055040.0000\n",
      "Epoch 166/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6393 - loss: -23664609280.0000 - val_accuracy: 0.6277 - val_loss: -28274073600.0000\n",
      "Epoch 167/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6362 - loss: -24770818048.0000 - val_accuracy: 0.6277 - val_loss: -26640560128.0000\n",
      "Epoch 168/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6225 - loss: -25429815296.0000 - val_accuracy: 0.6277 - val_loss: -27586306048.0000\n",
      "Epoch 169/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6211 - loss: -26278574080.0000 - val_accuracy: 0.6277 - val_loss: -30641074176.0000\n",
      "Epoch 170/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6358 - loss: -26206887936.0000 - val_accuracy: 0.6277 - val_loss: -30083690496.0000\n",
      "Epoch 171/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6332 - loss: -26970798080.0000 - val_accuracy: 0.6277 - val_loss: -30375546880.0000\n",
      "Epoch 172/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6376 - loss: -27369734144.0000 - val_accuracy: 0.6277 - val_loss: -31189090304.0000\n",
      "Epoch 173/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6401 - loss: -27743191040.0000 - val_accuracy: 0.6277 - val_loss: -31054569472.0000\n",
      "Epoch 174/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6360 - loss: -28198948864.0000 - val_accuracy: 0.6277 - val_loss: -32585596928.0000\n",
      "Epoch 175/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6323 - loss: -29500012544.0000 - val_accuracy: 0.6277 - val_loss: -32646455296.0000\n",
      "Epoch 176/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6407 - loss: -29544210432.0000 - val_accuracy: 0.6277 - val_loss: -33073534976.0000\n",
      "Epoch 177/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6402 - loss: -29726914560.0000 - val_accuracy: 0.6277 - val_loss: -33862883328.0000\n",
      "Epoch 178/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6438 - loss: -30824179712.0000 - val_accuracy: 0.6277 - val_loss: -34274942976.0000\n",
      "Epoch 179/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6376 - loss: -31695177728.0000 - val_accuracy: 0.6277 - val_loss: -34982174720.0000\n",
      "Epoch 180/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6357 - loss: -32034127872.0000 - val_accuracy: 0.6277 - val_loss: -34871496704.0000\n",
      "Epoch 181/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6335 - loss: -33270411264.0000 - val_accuracy: 0.6277 - val_loss: -37586010112.0000\n",
      "Epoch 182/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6274 - loss: -33938561024.0000 - val_accuracy: 0.6277 - val_loss: -38213222400.0000\n",
      "Epoch 183/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6363 - loss: -34119565312.0000 - val_accuracy: 0.6277 - val_loss: -38512857088.0000\n",
      "Epoch 184/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6454 - loss: -34328092672.0000 - val_accuracy: 0.6277 - val_loss: -40627400704.0000\n",
      "Epoch 185/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6331 - loss: -36016181248.0000 - val_accuracy: 0.6277 - val_loss: -40042708992.0000\n",
      "Epoch 186/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6264 - loss: -36671434752.0000 - val_accuracy: 0.6277 - val_loss: -40804274176.0000\n",
      "Epoch 187/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6291 - loss: -37905850368.0000 - val_accuracy: 0.6277 - val_loss: -40705613824.0000\n",
      "Epoch 188/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6323 - loss: -37734543360.0000 - val_accuracy: 0.6277 - val_loss: -42503483392.0000\n",
      "Epoch 189/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6400 - loss: -38154563584.0000 - val_accuracy: 0.6277 - val_loss: -41931173888.0000\n",
      "Epoch 190/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6436 - loss: -38896308224.0000 - val_accuracy: 0.6277 - val_loss: -42618343424.0000\n",
      "Epoch 191/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6255 - loss: -40734150656.0000 - val_accuracy: 0.6277 - val_loss: -49757335552.0000\n",
      "Epoch 192/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6266 - loss: -41579671552.0000 - val_accuracy: 0.6277 - val_loss: -45260304384.0000\n",
      "Epoch 193/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6405 - loss: -40877551616.0000 - val_accuracy: 0.6277 - val_loss: -48405123072.0000\n",
      "Epoch 194/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6396 - loss: -42771591168.0000 - val_accuracy: 0.6277 - val_loss: -45677965312.0000\n",
      "Epoch 195/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6394 - loss: -42957107200.0000 - val_accuracy: 0.6277 - val_loss: -46980100096.0000\n",
      "Epoch 196/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6247 - loss: -44267200512.0000 - val_accuracy: 0.6277 - val_loss: -48567963648.0000\n",
      "Epoch 197/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6431 - loss: -43963936768.0000 - val_accuracy: 0.6277 - val_loss: -48504037376.0000\n",
      "Epoch 198/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6341 - loss: -45882142720.0000 - val_accuracy: 0.6277 - val_loss: -52158976000.0000\n",
      "Epoch 199/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6429 - loss: -46156021760.0000 - val_accuracy: 0.6277 - val_loss: -49856577536.0000\n",
      "Epoch 200/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6325 - loss: -47151570944.0000 - val_accuracy: 0.6277 - val_loss: -52876283904.0000\n",
      "Epoch 201/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6405 - loss: -47854047232.0000 - val_accuracy: 0.6277 - val_loss: -55637733376.0000\n",
      "Epoch 202/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6473 - loss: -48043528192.0000 - val_accuracy: 0.6277 - val_loss: -53466587136.0000\n",
      "Epoch 203/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6335 - loss: -49786843136.0000 - val_accuracy: 0.6277 - val_loss: -56062148608.0000\n",
      "Epoch 204/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6351 - loss: -50073018368.0000 - val_accuracy: 0.6277 - val_loss: -53992488960.0000\n",
      "Epoch 205/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6481 - loss: -50828947456.0000 - val_accuracy: 0.6277 - val_loss: -57149874176.0000\n",
      "Epoch 206/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6355 - loss: -52150935552.0000 - val_accuracy: 0.6277 - val_loss: -59806679040.0000\n",
      "Epoch 207/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6393 - loss: -53159985152.0000 - val_accuracy: 0.6277 - val_loss: -57852493824.0000\n",
      "Epoch 208/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6361 - loss: -53787664384.0000 - val_accuracy: 0.6277 - val_loss: -58306322432.0000\n",
      "Epoch 209/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6358 - loss: -56082960384.0000 - val_accuracy: 0.6277 - val_loss: -63626522624.0000\n",
      "Epoch 210/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6424 - loss: -55854841856.0000 - val_accuracy: 0.6277 - val_loss: -65550585856.0000\n",
      "Epoch 211/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6308 - loss: -57571168256.0000 - val_accuracy: 0.6277 - val_loss: -64175792128.0000\n",
      "Epoch 212/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6281 - loss: -59029188608.0000 - val_accuracy: 0.6277 - val_loss: -67119362048.0000\n",
      "Epoch 213/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6380 - loss: -59081007104.0000 - val_accuracy: 0.6277 - val_loss: -64352452608.0000\n",
      "Epoch 214/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6378 - loss: -59486740480.0000 - val_accuracy: 0.6277 - val_loss: -70175752192.0000\n",
      "Epoch 215/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6346 - loss: -62237638656.0000 - val_accuracy: 0.6277 - val_loss: -68593582080.0000\n",
      "Epoch 216/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6348 - loss: -61516201984.0000 - val_accuracy: 0.6277 - val_loss: -69474549760.0000\n",
      "Epoch 217/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6407 - loss: -63367921664.0000 - val_accuracy: 0.6277 - val_loss: -69813174272.0000\n",
      "Epoch 218/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6403 - loss: -62837534720.0000 - val_accuracy: 0.6277 - val_loss: -65110007808.0000\n",
      "Epoch 219/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6360 - loss: -65649238016.0000 - val_accuracy: 0.6277 - val_loss: -75020861440.0000\n",
      "Epoch 220/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6415 - loss: -66749067264.0000 - val_accuracy: 0.6277 - val_loss: -71988404224.0000\n",
      "Epoch 221/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6372 - loss: -67655467008.0000 - val_accuracy: 0.6277 - val_loss: -76481880064.0000\n",
      "Epoch 222/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6342 - loss: -69434384384.0000 - val_accuracy: 0.6277 - val_loss: -76309200896.0000\n",
      "Epoch 223/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6418 - loss: -69027356672.0000 - val_accuracy: 0.6277 - val_loss: -79366217728.0000\n",
      "Epoch 224/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6374 - loss: -71352672256.0000 - val_accuracy: 0.6277 - val_loss: -78368202752.0000\n",
      "Epoch 225/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6223 - loss: -74694352896.0000 - val_accuracy: 0.6277 - val_loss: -83501301760.0000\n",
      "Epoch 226/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6298 - loss: -73839443968.0000 - val_accuracy: 0.6277 - val_loss: -80584523776.0000\n",
      "Epoch 227/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6347 - loss: -74859290624.0000 - val_accuracy: 0.6277 - val_loss: -85435449344.0000\n",
      "Epoch 228/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6327 - loss: -78145380352.0000 - val_accuracy: 0.6277 - val_loss: -88242429952.0000\n",
      "Epoch 229/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6210 - loss: -79940280320.0000 - val_accuracy: 0.6277 - val_loss: -87224090624.0000\n",
      "Epoch 230/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6307 - loss: -78235328512.0000 - val_accuracy: 0.6277 - val_loss: -90173120512.0000\n",
      "Epoch 231/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6302 - loss: -80496852992.0000 - val_accuracy: 0.6277 - val_loss: -87863427072.0000\n",
      "Epoch 232/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6400 - loss: -80466313216.0000 - val_accuracy: 0.6277 - val_loss: -91583406080.0000\n",
      "Epoch 233/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6319 - loss: -82268725248.0000 - val_accuracy: 0.6277 - val_loss: -92652986368.0000\n",
      "Epoch 234/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6222 - loss: -86000435200.0000 - val_accuracy: 0.6277 - val_loss: -93391060992.0000\n",
      "Epoch 235/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6343 - loss: -86774800384.0000 - val_accuracy: 0.6277 - val_loss: -95846998016.0000\n",
      "Epoch 236/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6448 - loss: -87307296768.0000 - val_accuracy: 0.6277 - val_loss: -94237245440.0000\n",
      "Epoch 237/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6500 - loss: -85011210240.0000 - val_accuracy: 0.6277 - val_loss: -92758097920.0000\n",
      "Epoch 238/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6398 - loss: -88397250560.0000 - val_accuracy: 0.6277 - val_loss: -103214710784.0000\n",
      "Epoch 239/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6377 - loss: -91255504896.0000 - val_accuracy: 0.6277 - val_loss: -101755084800.0000\n",
      "Epoch 240/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6412 - loss: -90663608320.0000 - val_accuracy: 0.6277 - val_loss: -104540889088.0000\n",
      "Epoch 241/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6372 - loss: -92707979264.0000 - val_accuracy: 0.6277 - val_loss: -108023316480.0000\n",
      "Epoch 242/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6322 - loss: -95632850944.0000 - val_accuracy: 0.6277 - val_loss: -106437500928.0000\n",
      "Epoch 243/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6379 - loss: -96562135040.0000 - val_accuracy: 0.6277 - val_loss: -108304244736.0000\n",
      "Epoch 244/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6221 - loss: -99167870976.0000 - val_accuracy: 0.6277 - val_loss: -108899852288.0000\n",
      "Epoch 245/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6429 - loss: -97433657344.0000 - val_accuracy: 0.6277 - val_loss: -113130897408.0000\n",
      "Epoch 246/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6390 - loss: -100933074944.0000 - val_accuracy: 0.6277 - val_loss: -112071827456.0000\n",
      "Epoch 247/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6502 - loss: -101110956032.0000 - val_accuracy: 0.6277 - val_loss: -112198221824.0000\n",
      "Epoch 248/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6380 - loss: -103094272000.0000 - val_accuracy: 0.6277 - val_loss: -114561548288.0000\n",
      "Epoch 249/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6376 - loss: -106074791936.0000 - val_accuracy: 0.6277 - val_loss: -116005314560.0000\n",
      "Epoch 250/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6356 - loss: -106425212928.0000 - val_accuracy: 0.6277 - val_loss: -116513316864.0000\n",
      "Epoch 251/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6405 - loss: -109259112448.0000 - val_accuracy: 0.6277 - val_loss: -116704370688.0000\n",
      "Epoch 252/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6405 - loss: -109278429184.0000 - val_accuracy: 0.6277 - val_loss: -123438546944.0000\n",
      "Epoch 253/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6438 - loss: -111107047424.0000 - val_accuracy: 0.6277 - val_loss: -122565967872.0000\n",
      "Epoch 254/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6407 - loss: -110842691584.0000 - val_accuracy: 0.6277 - val_loss: -123809005568.0000\n",
      "Epoch 255/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6407 - loss: -113396219904.0000 - val_accuracy: 0.6277 - val_loss: -131588710400.0000\n",
      "Epoch 256/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6331 - loss: -117703598080.0000 - val_accuracy: 0.6277 - val_loss: -132112736256.0000\n",
      "Epoch 257/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6366 - loss: -117914517504.0000 - val_accuracy: 0.6277 - val_loss: -129436180480.0000\n",
      "Epoch 258/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6314 - loss: -121154854912.0000 - val_accuracy: 0.6277 - val_loss: -129475936256.0000\n",
      "Epoch 259/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6420 - loss: -120314839040.0000 - val_accuracy: 0.6277 - val_loss: -137943842816.0000\n",
      "Epoch 260/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6281 - loss: -124399247360.0000 - val_accuracy: 0.6277 - val_loss: -135035518976.0000\n",
      "Epoch 261/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6235 - loss: -128200810496.0000 - val_accuracy: 0.6277 - val_loss: -141170442240.0000\n",
      "Epoch 262/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: -127041413120.0000 - val_accuracy: 0.6277 - val_loss: -139658231808.0000\n",
      "Epoch 263/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6306 - loss: -129627873280.0000 - val_accuracy: 0.6277 - val_loss: -142245396480.0000\n",
      "Epoch 264/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6365 - loss: -130122924032.0000 - val_accuracy: 0.6277 - val_loss: -144255483904.0000\n",
      "Epoch 265/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6412 - loss: -132644691968.0000 - val_accuracy: 0.6277 - val_loss: -143683993600.0000\n",
      "Epoch 266/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6331 - loss: -137193594880.0000 - val_accuracy: 0.6277 - val_loss: -148501331968.0000\n",
      "Epoch 267/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6287 - loss: -137406226432.0000 - val_accuracy: 0.6277 - val_loss: -151495557120.0000\n",
      "Epoch 268/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6362 - loss: -140081512448.0000 - val_accuracy: 0.6277 - val_loss: -164631543808.0000\n",
      "Epoch 269/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6385 - loss: -140038373376.0000 - val_accuracy: 0.6277 - val_loss: -152080515072.0000\n",
      "Epoch 270/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6310 - loss: -145849794560.0000 - val_accuracy: 0.6277 - val_loss: -159401705472.0000\n",
      "Epoch 271/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6336 - loss: -145162289152.0000 - val_accuracy: 0.6277 - val_loss: -169387851776.0000\n",
      "Epoch 272/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6391 - loss: -145915772928.0000 - val_accuracy: 0.6277 - val_loss: -163407413248.0000\n",
      "Epoch 273/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6413 - loss: -145708941312.0000 - val_accuracy: 0.6277 - val_loss: -166111100928.0000\n",
      "Epoch 274/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6294 - loss: -150912466944.0000 - val_accuracy: 0.6277 - val_loss: -166990397440.0000\n",
      "Epoch 275/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6353 - loss: -154590986240.0000 - val_accuracy: 0.6277 - val_loss: -170891640832.0000\n",
      "Epoch 276/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6309 - loss: -153127567360.0000 - val_accuracy: 0.6277 - val_loss: -163557539840.0000\n",
      "Epoch 277/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6292 - loss: -157832953856.0000 - val_accuracy: 0.6277 - val_loss: -174727561216.0000\n",
      "Epoch 278/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6325 - loss: -159551832064.0000 - val_accuracy: 0.6277 - val_loss: -180635418624.0000\n",
      "Epoch 279/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6302 - loss: -163082551296.0000 - val_accuracy: 0.6277 - val_loss: -169359327232.0000\n",
      "Epoch 280/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6274 - loss: -163321823232.0000 - val_accuracy: 0.6277 - val_loss: -178402361344.0000\n",
      "Epoch 281/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6377 - loss: -163702472704.0000 - val_accuracy: 0.6277 - val_loss: -180877983744.0000\n",
      "Epoch 282/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6339 - loss: -170111369216.0000 - val_accuracy: 0.6277 - val_loss: -186345422848.0000\n",
      "Epoch 283/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6321 - loss: -169372893184.0000 - val_accuracy: 0.6277 - val_loss: -187205025792.0000\n",
      "Epoch 284/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6406 - loss: -171784486912.0000 - val_accuracy: 0.6277 - val_loss: -193995489280.0000\n",
      "Epoch 285/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6412 - loss: -173396082688.0000 - val_accuracy: 0.6277 - val_loss: -195986194432.0000\n",
      "Epoch 286/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6350 - loss: -174977990656.0000 - val_accuracy: 0.6277 - val_loss: -202687070208.0000\n",
      "Epoch 287/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6370 - loss: -178233344000.0000 - val_accuracy: 0.6277 - val_loss: -190878072832.0000\n",
      "Epoch 288/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6294 - loss: -182130114560.0000 - val_accuracy: 0.6277 - val_loss: -200245362688.0000\n",
      "Epoch 289/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6267 - loss: -184500371456.0000 - val_accuracy: 0.6277 - val_loss: -204402933760.0000\n",
      "Epoch 290/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6391 - loss: -181257928704.0000 - val_accuracy: 0.6277 - val_loss: -199870021632.0000\n",
      "Epoch 291/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6326 - loss: -188518678528.0000 - val_accuracy: 0.6277 - val_loss: -213084766208.0000\n",
      "Epoch 292/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6272 - loss: -191960481792.0000 - val_accuracy: 0.6277 - val_loss: -219613380608.0000\n",
      "Epoch 293/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6370 - loss: -194124955648.0000 - val_accuracy: 0.6277 - val_loss: -213920940032.0000\n",
      "Epoch 294/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6383 - loss: -190992908288.0000 - val_accuracy: 0.6277 - val_loss: -215443800064.0000\n",
      "Epoch 295/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6256 - loss: -201255124992.0000 - val_accuracy: 0.6277 - val_loss: -217617956864.0000\n",
      "Epoch 296/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6250 - loss: -203177984000.0000 - val_accuracy: 0.6277 - val_loss: -225602977792.0000\n",
      "Epoch 297/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6380 - loss: -202041868288.0000 - val_accuracy: 0.6277 - val_loss: -222747754496.0000\n",
      "Epoch 298/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6337 - loss: -204861177856.0000 - val_accuracy: 0.6277 - val_loss: -219943337984.0000\n",
      "Epoch 299/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6403 - loss: -206065647616.0000 - val_accuracy: 0.6277 - val_loss: -226858942464.0000\n",
      "Epoch 300/300\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6330 - loss: -209489477632.0000 - val_accuracy: 0.6277 - val_loss: -227042066432.0000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,epochs=300,batch_size=18, validation_split=.20, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e18fea1-38b7-4ba4-b805-3c27c27d842f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,440</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">47,236</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">28,368</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,240</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,848</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,984</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,380</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">594</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)                 │           \u001b[38;5;34m7,440\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m)                 │          \u001b[38;5;34m47,236\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)                 │          \u001b[38;5;34m28,368\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)                 │             \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)                 │          \u001b[38;5;34m16,240\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │          \u001b[38;5;34m10,848\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m)                  │           \u001b[38;5;34m6,984\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m)                  │             \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)                  │           \u001b[38;5;34m4,380\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │           \u001b[38;5;34m2,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m1,568\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m594\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m114\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m7\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">382,107</span> (1.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m382,107\u001b[0m (1.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">127,203</span> (496.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m127,203\u001b[0m (496.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">496</span> (1.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m496\u001b[0m (1.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">254,408</span> (993.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m254,408\u001b[0m (993.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "acb8eb3f-1efb-480b-9032-1a6c3c195745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23abc4169f0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"],label=\"Accuracy\")         #Eğitim kümesinin dogrulugu\n",
    "plt.plot(history.history[\"val_accuracy\"],label=\"Val_Accuracy\") # Dogrulama kümesinin dogrulugu\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd602c2-5898-4d52-b695-051d6f2083f0",
   "metadata": {},
   "source": [
    "Classification da \"y\" deki kuşakları yazı şeklinde girip label encoder yapınca accuracy score çok düşük çıkıyor \n",
    "; Ancak kuşakalra en başta 1,2,3 şeklinde değer verince accuradcy score normal değerlerde çıkıyor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fatsergpu)",
   "language": "python",
   "name": "fatsergpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
